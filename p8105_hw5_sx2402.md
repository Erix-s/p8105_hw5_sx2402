p8105_hw5_sx2402
================
Eric Xu
2025-11-02

## Problem 1

1.  Creating a function generating random birthdays.

``` r
has_shared_birthday = function(n) {
  if (!is.numeric(n)) {
    stop("Argument n should be numeric")
  } else {
    birthdays = sample(1:365, size = n, replace = TRUE)
    return(length(unique(birthdays)) < n)
  }
}
```

2.  Simulating and plotting.

``` r
n_sim = 10000
group_sizes = 2:50
results = tibble()
for (n in group_sizes) {
  shared_vector = logical(n_sim)
  
  for (i in 1:n_sim) {
    shared_vector[i] = has_shared_birthday(n)
  }
  prob_shared = mean(shared_vector)
  
  results = bind_rows(results, tibble(group_size = n, prob_shared = prob_shared))
}

results |> ggplot(aes(x=group_size, y = prob_shared))+geom_point(size = 2, color = "black")+geom_smooth(method = 'loess',formula = y~x, alpha = 0.8, linewidth = 0.6)
```

![](p8105_hw5_sx2402_files/figure-gfm/Q1%20run-1.png)<!-- -->

## Problem 2

1.  Creating a function generating random normal distribution values.

``` r
sim_ttest = function(mu_true, n = 30, sigma = 5, n_sim = 5000) {
  result = vector("list",5000)
  for (i in 1:n_sim){
      x = rnorm(n, mean = mu_true, sd = sigma)
      ttest = broom::tidy(t.test(x, mu = 0,conf.level = 0.95))
      run = tibble(
      mu_hat = ttest$estimate,
      p_value = ttest$p.value
  )
  result[[i]] = run
  }
  bind_rows(result)
}
```

2.  Simulation

``` r
sim_results_df = 
  expand_grid(
    mu_values = 0:6
  ) |> 
  mutate(
    estimate_df = map(mu_values, sim_ttest)
  ) |> 
  unnest(estimate_df)

power_results = sim_results_df |> 
  group_by(mu_values) |> 
  summarize(power = mean(p_value < 0.05))


ggplot(power_results, aes(x = mu_values, y = power)) +
  geom_line(linewidth = 1.2, color = "steelblue") +
  geom_point(size = 2, color = "darkred") +
  labs(
    title = "Power Curve for One-Sample t-Test",
    x = "True Mean (μ)",
    y = "Power by reject proportion"
  ) +
  theme_minimal()
```

![](p8105_hw5_sx2402_files/figure-gfm/Q2%20sim-1.png)<!-- -->

``` r
mu_summary = sim_results_df |> 
  group_by(mu_values) |> 
  summarize(
    mean_mu_select = mean(mu_hat[p_value < 0.05]),
    mu_hat_mean = mean(mu_hat),
  )

ggplot(mu_summary, aes(x = mu_values)) +
  geom_line(aes(y = mu_hat_mean, color = "All samples")) +
  geom_point(aes(y = mu_hat_mean, color = "All samples")) +
  geom_line(aes(y = mean_mu_select, color = "Significant only")) +
  geom_point(aes(y = mean_mu_select, color = "Significant only")) +
  labs(
    title = "Average Estimates vs True μ",
    x = "True Mean",
    y = "Average Estimate",
    color = "Condition"
  ) +
  scale_color_manual(values = c("All samples" = "steelblue", "Significant only" = "darkred")) +
  theme_minimal()
```

![](p8105_hw5_sx2402_files/figure-gfm/Q2%20sim-2.png)<!-- -->

3.  Explanation

<!-- -->

1.  The power Curve for t-test shows a sigmoid distribution from 0 to 1.
    This is seemingly resulted by cumulative probability with increase
    of true mu.

2.  When condition on rejecting the null, selecting samples causes bias.
    For small true effects , most samples won’t reach significance. with
    True Mean close to 0, a proportion of estimates has hypothesis not
    rejected. The filtered set will likely to have higher mean estimates
    that resulting in biased average estimates. Therefore, for which the
    null is rejected is not approximately equal to the true value
    compared to all samples included at a lower effect from 1 to 4. And
    for 0 a smaller number of sets falsely rejected the value.

\##Problem 2
